import aiohttp
import asyncio
import json
import os
from notify import send
from bs4 import BeautifulSoup

def load_cookies():
    global amazon_cookies
    cookie_file = "amazon_cookies.json"
    with open(cookie_file, "r") as f:
        amazon_cookies = json.loads(f.read())

def get_urls():
    urls_str = os.getenv('amazon_urls', '')
    
    # ä½¿ç”¨æ¢è¡Œç¬¦åˆ†å‰² URL
    urls = [url.strip() for url in urls_str.split('\n') if url.strip()]
    return urls

async def fetch_amazon_product(url):
    params = {
        "linkCode": "sl1",
        "tag": "twm1a4080-22",
        "linkId": "387fac7c4d0581478539f94f3afea1ff",
        "language": "ja_JP",
        "ref_": "as_li_ss_tl"
    }
    headers = {
        "accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7",
        "accept-language": "en-US,en;q=0.9",
        "cache-control": "max-age=0",
        "device-memory": "4",
        "downlink": "10",
        "dpr": "1",
        "ect": "4g",
        "priority": "u=0, i",
        "rtt": "50",
        "sec-ch-device-memory": "4",
        "sec-ch-dpr": "1",
        "sec-ch-ua": '"Chromium";v="129", "Not=A?Brand";v="8"',
        "sec-ch-ua-mobile": "?1",
        "sec-ch-ua-platform": '"Android"',
        "sec-ch-ua-platform-version": '"6.0"',
        "sec-ch-viewport-width": "400",
        "sec-fetch-dest": "document",
        "sec-fetch-mode": "navigate",
        "sec-fetch-site": "none",
        "sec-fetch-user": "?1",
        "upgrade-insecure-requests": "1",
        "user-agent": "Mozilla/5.0 (Linux; Android 6.0; Nexus 5 Build/MRA58N) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/129.0.0.0 Mobile Safari/537.36",
        "viewport-width": "400"
    }

    cookie_file = "amazon_cookies.json"
    with open(cookie_file, "r") as f:
        amazon_cookies = json.loads(f.read())
    proxy = os.getenv('http_proxy')
        
    # ä½¿ç”¨ä»£ç†å‘é€è¯·æ±‚
    async with aiohttp.ClientSession() as session:
        try:
            async with session.get(
                    url,
                    params=params, 
                    headers=headers, 
                    cookies=amazon_cookies,
                    proxy=proxy) as response:
                if response.status == 200:
                    return await response.text()
                else:
                    print(f"è¯·æ±‚å¤±è´¥ï¼ŒçŠ¶æ€ç ï¼š{response.status}")
                    return None
        except Exception as e:
            print(f"å‘ç”Ÿé”™è¯¯ï¼š{str(e)}")
            return None



async def main():
    urls = get_urls()
    load_cookies()
    for url in urls:
        result = await fetch_amazon_product(url)
        if result:
            print("è¯·æ±‚æˆåŠŸï¼")
            soup = BeautifulSoup(result, 'html.parser')
            try:
                add_to_cart_element = soup.find('input', {'id': 'add-to-cart-button'})

                if add_to_cart_element:
                    product_title = soup.find('meta', attrs={'name': 'title'})['content']
                    
                    # å‘é€é€šçŸ¥
                    send(
                        title='ğŸ¯ Amazon å‘ç°ç›®æ ‡å•†å“ï¼',
                        content=f'''## {product_title}

> **ç›´è¾¾é“¾æ¥ï¼š**
> [ç‚¹å‡»è´­ä¹°]({url})

---
åŸå§‹é“¾æ¥ï¼š{url}'''
                    )
                    print("å·²å‘é€åº“å­˜é€šçŸ¥")
                else:
                    print("å•†å“æš‚æ— åº“å­˜")
                
            except Exception as e:
                print(f"æ£€æŸ¥åº“å­˜æ—¶å‡ºé”™: {str(e)}")
    
if __name__ == "__main__":
    asyncio.run(main())














